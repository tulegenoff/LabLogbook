{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quDlLWcAP31q"
   },
   "source": [
    "## MLP for Binary Classification\n",
    "\n",
    "In this lab, you will use the Ionosphere data binary (two-class) classification dataset to demonstrate an MLP for binary classification.\n",
    "\n",
    "This dataset involves predicting whether a structure is in the atmosphere or not given radar returns.\n",
    "\n",
    "The dataset will be downloaded automatically using Pandas, but you can learn more in the links below.\n",
    "\n",
    "[Ionosphere Dataset (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv)\n",
    "\n",
    "[Ionosphere Dataset Description (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.names)\n",
    "\n",
    "\n",
    "Your task for this is lab is to develop a Keras-based Multi-Layer Perceptron model for this data set. Remember the number of output layers is equal to the number of classes.\n",
    "\n",
    "Following we have provided some piece of code to you while you need to complete the rest of the code on your own.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6086ipzNP31q",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tulegenoff\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Your code to import read_csv class from pandas\n",
    "# Your code to import train_test_split class from sklearn. Follow link https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7755rFn_iDRj"
   },
   "source": [
    "# Read the dataset from the path below. Store the data in a pandas dataframe named 'df'\n",
    "\n",
    "Link to API - https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "058u-qkXP31r",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1        2        3        4        5        6        7        8   \\\n",
       "0   1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
       "1   1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
       "2   1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
       "3   1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
       "4   1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
       "\n",
       "        9   ...       25       26       27       28       29       30  \\\n",
       "0  0.03760  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267   \n",
       "1 -0.04549  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
       "2  0.01198  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
       "3  0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
       "4 -0.16399  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
       "\n",
       "        31       32       33  34  \n",
       "0 -0.54487  0.18641 -0.45300   g  \n",
       "1 -0.06288 -0.13738 -0.02447   b  \n",
       "2 -0.24180  0.56045 -0.38238   g  \n",
       "3  1.00000 -0.32382  1.00000   b  \n",
       "4 -0.59573 -0.04608 -0.65697   g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n",
    "# Your code to read the csv from the above path.\n",
    "df = pd.read_csv(path, header = None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vG3n2OHrjQsG"
   },
   "source": [
    "See the sample dataset. Print few rows of the dataset. Use dataframe.head() method.\n",
    "\n",
    "Link to API:  https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jx3JTj4sfUIt",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.3409</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.453</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1        2        3        4        5        6        7    8       9   \\\n",
       "0   1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.0  0.0376   \n",
       "\n",
       "   ...       25       26       27       28      29       30       31       32  \\\n",
       "0  ... -0.51171  0.41078 -0.46168  0.21266 -0.3409  0.42267 -0.54487  0.18641   \n",
       "\n",
       "      33  34  \n",
       "0 -0.453   g  \n",
       "\n",
       "[1 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code to print first few rows of the dataset.\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uo8Siqyxfhj7"
   },
   "source": [
    "Print the basic info of the dataset. Use dataframe.info() from pandas library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VgN9rYV_fiag",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 351 entries, 0 to 350\n",
      "Data columns (total 35 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       351 non-null    int64  \n",
      " 1   1       351 non-null    int64  \n",
      " 2   2       351 non-null    float64\n",
      " 3   3       351 non-null    float64\n",
      " 4   4       351 non-null    float64\n",
      " 5   5       351 non-null    float64\n",
      " 6   6       351 non-null    float64\n",
      " 7   7       351 non-null    float64\n",
      " 8   8       351 non-null    float64\n",
      " 9   9       351 non-null    float64\n",
      " 10  10      351 non-null    float64\n",
      " 11  11      351 non-null    float64\n",
      " 12  12      351 non-null    float64\n",
      " 13  13      351 non-null    float64\n",
      " 14  14      351 non-null    float64\n",
      " 15  15      351 non-null    float64\n",
      " 16  16      351 non-null    float64\n",
      " 17  17      351 non-null    float64\n",
      " 18  18      351 non-null    float64\n",
      " 19  19      351 non-null    float64\n",
      " 20  20      351 non-null    float64\n",
      " 21  21      351 non-null    float64\n",
      " 22  22      351 non-null    float64\n",
      " 23  23      351 non-null    float64\n",
      " 24  24      351 non-null    float64\n",
      " 25  25      351 non-null    float64\n",
      " 26  26      351 non-null    float64\n",
      " 27  27      351 non-null    float64\n",
      " 28  28      351 non-null    float64\n",
      " 29  29      351 non-null    float64\n",
      " 30  30      351 non-null    float64\n",
      " 31  31      351 non-null    float64\n",
      " 32  32      351 non-null    float64\n",
      " 33  33      351 non-null    float64\n",
      " 34  34      351 non-null    object \n",
      "dtypes: float64(32), int64(2), object(1)\n",
      "memory usage: 96.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Your code to print information about the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AX_YFAb4kdl4"
   },
   "source": [
    "Print the shape of the dataframe. Select suitable API call from the pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rlfCOssvf44O",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 35)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code to print the shape of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aekdoY2zkxU4"
   },
   "source": [
    "# Separate the input and output from the dataframe. Input is all columns besides last column. Output is the last column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_5bh8al2P31s",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.values[:, :-1]\n",
    "# Your code to get y - Hint y = df.values[:, some parameters]\n",
    "y = df.values[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7y3GhJDloqk"
   },
   "source": [
    "We have converted everthing in X to 'float' and the letters in column y to the numbers in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qVtPf2F9lg17",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "y = LabelEncoder().fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZ_aY4H3l9bI"
   },
   "source": [
    "Printing the genral information of the X and y in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BWBOMrBigew9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X values:\n",
      " [[ 1.       0.       0.99539 ... -0.54487  0.18641 -0.453  ]\n",
      " [ 1.       0.       1.      ... -0.06288 -0.13738 -0.02447]\n",
      " [ 1.       0.       1.      ... -0.2418   0.56045 -0.38238]\n",
      " ...\n",
      " [ 1.       0.       0.94701 ...  0.00442  0.92697 -0.00577]\n",
      " [ 1.       0.       0.90608 ... -0.03757  0.87403 -0.16243]\n",
      " [ 1.       0.       0.8471  ... -0.06678  0.85764 -0.06151]]\n",
      "y values:\n",
      " [1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Shape of dataset:\n",
      " (351, 34)\n",
      "Shape of y:\n",
      " (351,)\n"
     ]
    }
   ],
   "source": [
    "# Your code to print X\n",
    "# Your code to print y\n",
    "# your code to print shape of X. Remember X is a numpy array\n",
    "# your code to print shape of y. Remember y is a numpy array\n",
    "print('X values:\\n', X)\n",
    "print('y values:\\n', y)\n",
    "print('Shape of dataset:\\n', X.shape)\n",
    "print('Shape of y:\\n', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9ltrLLqmkgW"
   },
   "source": [
    "* Separate X and y into training and test set with a ratio of your choice.\n",
    "* Print the shapes of the resulting arrays.\n",
    "* Get the number of features from X_train. Remember the number of features are the number of inputs.\n",
    "\n",
    "Use sklearn train_test_split class.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-CjFJcAMP31s",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(245, 34)\n",
      "(245,)\n",
      "(106, 34)\n",
      "(106,)\n"
     ]
    }
   ],
   "source": [
    "# Your code to separate the data into trauning and test set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, random_state=123)\n",
    "# Your code to print shape of X_train\n",
    "print(X_train.shape)\n",
    "# Your code to print shape of X_test\n",
    "print(y_train.shape)\n",
    "# Your code to print shape of y_train\n",
    "print(X_test.shape)\n",
    "# Your code to print shape of X_test\n",
    "print(y_test.shape)\n",
    "\n",
    "n_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQdqYXJ9pqzC"
   },
   "source": [
    "# Creating a Multi-layer Perceptron using Keras.\n",
    "We have added first and last layers. Create the hidden layers of your choise.\n",
    "You can chose any number of hidden layers and activation function of your chose\n",
    "https://keras.io/api/layers/core_layers/dense/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "hhTE3u-_P31t",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
    "#\n",
    "# Add as many layers with activation functions of your choice\n",
    "model.add(Dense(5, activation = 'relu'))\n",
    "#\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_25 (Dense)            (None, 10)                350       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 411 (1.61 KB)\n",
      "Trainable params: 411 (1.61 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NtBU922rH67"
   },
   "source": [
    "In the next cell, we trained the above neural network model and tested its accuracy. As this concept has still not benn covered in the class, just run the code to check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "krgB1SuRP31t",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.925\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)\n",
    "\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ReYGy_jsCh0"
   },
   "source": [
    "** How much accuracy have you got? Compare the accuracy with your peers. **\n",
    "** Now, change your model and activation function to get the better accuracy as compared to your peers **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.934\n",
      "Test loss: 0.175\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Dense(20, activation='relu', input_shape = (n_features, )))\n",
    "model_2.add(Dense(10, activation = 'relu'))\n",
    "model_2.add(Dense(5, activation = 'relu'))\n",
    "model_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_2.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_2.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)\n",
    "\n",
    "loss_2, acc_2 = model_2.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Accuracy: %.3f' % acc_2)\n",
    "print('Test loss: %.3f' % loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "16/16 [==============================] - 2s 3ms/step - loss: 0.6029 - accuracy: 0.6776\n",
      "Epoch 2/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.8041\n",
      "Epoch 3/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.8367\n",
      "Epoch 4/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.8449\n",
      "Epoch 5/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.8571\n",
      "Epoch 6/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8612\n",
      "Epoch 7/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3608 - accuracy: 0.8612\n",
      "Epoch 8/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3375 - accuracy: 0.8735\n",
      "Epoch 9/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3185 - accuracy: 0.8816\n",
      "Epoch 10/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3001 - accuracy: 0.8980\n",
      "Epoch 11/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2814 - accuracy: 0.9020\n",
      "Epoch 12/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2671 - accuracy: 0.9061\n",
      "Epoch 13/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2517 - accuracy: 0.9061\n",
      "Epoch 14/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2381 - accuracy: 0.9143\n",
      "Epoch 15/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2260 - accuracy: 0.9265\n",
      "Epoch 16/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2120 - accuracy: 0.9306\n",
      "Epoch 17/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1986 - accuracy: 0.9347\n",
      "Epoch 18/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1886 - accuracy: 0.9347\n",
      "Epoch 19/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1777 - accuracy: 0.9429\n",
      "Epoch 20/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1676 - accuracy: 0.9429\n",
      "Epoch 21/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1594 - accuracy: 0.9469\n",
      "Epoch 22/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1503 - accuracy: 0.9551\n",
      "Epoch 23/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9633\n",
      "Epoch 24/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1393 - accuracy: 0.9592\n",
      "Epoch 25/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1319 - accuracy: 0.9673\n",
      "Epoch 26/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1250 - accuracy: 0.9673\n",
      "Epoch 27/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1217 - accuracy: 0.9673\n",
      "Epoch 28/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1183 - accuracy: 0.9714\n",
      "Epoch 29/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1099 - accuracy: 0.9755\n",
      "Epoch 30/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1089 - accuracy: 0.9755\n",
      "Epoch 31/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1012 - accuracy: 0.9796\n",
      "Epoch 32/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1005 - accuracy: 0.9714\n",
      "Epoch 33/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0965 - accuracy: 0.9878\n",
      "Epoch 34/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0934 - accuracy: 0.9837\n",
      "Epoch 35/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0881 - accuracy: 0.9837\n",
      "Epoch 36/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0849 - accuracy: 0.9837\n",
      "Epoch 37/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0826 - accuracy: 0.9878\n",
      "Epoch 38/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0814 - accuracy: 0.9837\n",
      "Epoch 39/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0797 - accuracy: 0.9837\n",
      "Epoch 40/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9837\n",
      "Epoch 41/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0743 - accuracy: 0.9796\n",
      "Epoch 42/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9878\n",
      "Epoch 43/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.9837\n",
      "Epoch 44/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9837\n",
      "Epoch 45/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9878\n",
      "Epoch 46/150\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0646 - accuracy: 0.9878\n",
      "Epoch 47/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.9878\n",
      "Epoch 48/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.9878\n",
      "Epoch 49/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.9837\n",
      "Epoch 50/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0563 - accuracy: 0.9878\n",
      "Epoch 51/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9878\n",
      "Epoch 52/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9878\n",
      "Epoch 53/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.9837\n",
      "Epoch 54/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9878\n",
      "Epoch 55/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9878\n",
      "Epoch 56/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0506 - accuracy: 0.9918\n",
      "Epoch 57/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.9918\n",
      "Epoch 58/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.9918\n",
      "Epoch 59/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9959\n",
      "Epoch 60/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.9918\n",
      "Epoch 61/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9918\n",
      "Epoch 62/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 0.9959\n",
      "Epoch 63/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9959\n",
      "Epoch 64/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9959\n",
      "Epoch 65/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0336 - accuracy: 0.9959\n",
      "Epoch 66/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0328 - accuracy: 0.9959\n",
      "Epoch 67/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0327 - accuracy: 0.9959\n",
      "Epoch 68/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0308 - accuracy: 0.9959\n",
      "Epoch 69/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.9959\n",
      "Epoch 70/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9959\n",
      "Epoch 71/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0275 - accuracy: 0.9959\n",
      "Epoch 72/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9959\n",
      "Epoch 73/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 0.9959\n",
      "Epoch 74/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.9959\n",
      "Epoch 75/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.9959\n",
      "Epoch 76/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0238 - accuracy: 0.9959\n",
      "Epoch 77/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0222 - accuracy: 0.9959\n",
      "Epoch 78/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.9959\n",
      "Epoch 79/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0209 - accuracy: 0.9959\n",
      "Epoch 80/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 0.9959\n",
      "Epoch 81/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 0.9959\n",
      "Epoch 82/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.9959\n",
      "Epoch 83/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9959\n",
      "Epoch 84/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.9959\n",
      "Epoch 85/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 0.9959\n",
      "Epoch 86/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 0.9959\n",
      "Epoch 87/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9959\n",
      "Epoch 90/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25c72abe590>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = Sequential()\n",
    "\n",
    "model_3.add(Dense(20, activation='selu', input_shape = (n_features, )))\n",
    "model_3.add(Dense(10, activation = 'selu'))\n",
    "model_3.add(Dense(5, activation='relu'))\n",
    "model_3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_3.fit(X_train, y_train, epochs=150, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.9434\n",
      "Test Accuracy: 0.943\n",
      "Test loss: 0.464\n"
     ]
    }
   ],
   "source": [
    "loss_3, acc_3 = model_3.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Accuracy: %.3f' % acc_3)\n",
    "print('Test loss: %.3f' % loss_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "16/16 [==============================] - 2s 3ms/step - loss: 0.6740 - accuracy: 0.6776\n",
      "Epoch 2/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7633\n",
      "Epoch 3/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5944 - accuracy: 0.7592\n",
      "Epoch 4/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.7633\n",
      "Epoch 5/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7959\n",
      "Epoch 6/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.8286\n",
      "Epoch 7/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8612\n",
      "Epoch 8/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3744 - accuracy: 0.8857\n",
      "Epoch 9/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3371 - accuracy: 0.8980\n",
      "Epoch 10/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3081 - accuracy: 0.9061\n",
      "Epoch 11/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2750 - accuracy: 0.9224\n",
      "Epoch 12/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2487 - accuracy: 0.9265\n",
      "Epoch 13/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2288 - accuracy: 0.9306\n",
      "Epoch 14/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2110 - accuracy: 0.9224\n",
      "Epoch 15/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1935 - accuracy: 0.9429\n",
      "Epoch 16/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1746 - accuracy: 0.9429\n",
      "Epoch 17/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1582 - accuracy: 0.9510\n",
      "Epoch 18/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1424 - accuracy: 0.9633\n",
      "Epoch 19/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1294 - accuracy: 0.9796\n",
      "Epoch 20/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1206 - accuracy: 0.9673\n",
      "Epoch 21/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1114 - accuracy: 0.9837\n",
      "Epoch 22/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1033 - accuracy: 0.9755\n",
      "Epoch 23/150\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0938 - accuracy: 0.9796\n",
      "Epoch 24/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0901 - accuracy: 0.9878\n",
      "Epoch 25/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0859 - accuracy: 0.9837\n",
      "Epoch 26/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0779 - accuracy: 0.9878\n",
      "Epoch 27/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0742 - accuracy: 0.9878\n",
      "Epoch 28/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0725 - accuracy: 0.9837\n",
      "Epoch 29/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.9918\n",
      "Epoch 30/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.9878\n",
      "Epoch 31/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.9878\n",
      "Epoch 32/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.9918\n",
      "Epoch 33/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9918\n",
      "Epoch 34/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9918\n",
      "Epoch 35/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9918\n",
      "Epoch 36/150\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0552 - accuracy: 0.9918\n",
      "Epoch 37/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9918\n",
      "Epoch 38/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9918\n",
      "Epoch 39/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9918\n",
      "Epoch 40/150\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 0.9918\n",
      "Epoch 41/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9918\n",
      "Epoch 42/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9918\n",
      "Epoch 43/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9918\n",
      "Epoch 44/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9918\n",
      "Epoch 45/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9918\n",
      "Epoch 46/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9918\n",
      "Epoch 47/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0455 - accuracy: 0.9918\n",
      "Epoch 48/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9918\n",
      "Epoch 49/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9918\n",
      "Epoch 50/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0430 - accuracy: 0.9918\n",
      "Epoch 51/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0419 - accuracy: 0.9918\n",
      "Epoch 52/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9918\n",
      "Epoch 53/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.9918\n",
      "Epoch 54/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9918\n",
      "Epoch 55/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9918\n",
      "Epoch 56/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9918\n",
      "Epoch 57/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9918\n",
      "Epoch 58/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9918\n",
      "Epoch 59/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0372 - accuracy: 0.9918\n",
      "Epoch 60/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9918\n",
      "Epoch 61/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.9918\n",
      "Epoch 62/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 0.9918\n",
      "Epoch 63/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 0.9918\n",
      "Epoch 64/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0344 - accuracy: 0.9918\n",
      "Epoch 65/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.9918\n",
      "Epoch 66/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 0.9918\n",
      "Epoch 67/150\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.9918\n",
      "Epoch 68/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9918\n",
      "Epoch 69/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.9918\n",
      "Epoch 70/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.9796\n",
      "Epoch 71/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9837\n",
      "Epoch 72/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0371 - accuracy: 0.9878\n",
      "Epoch 73/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - accuracy: 0.9918\n",
      "Epoch 74/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9918\n",
      "Epoch 75/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9918\n",
      "Epoch 76/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9959\n",
      "Epoch 77/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 0.9959\n",
      "Epoch 78/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9918\n",
      "Epoch 79/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9959\n",
      "Epoch 80/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9918\n",
      "Epoch 81/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9959\n",
      "Epoch 82/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9959\n",
      "Epoch 83/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9959\n",
      "Epoch 84/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9959\n",
      "Epoch 85/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9959\n",
      "Epoch 86/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9959\n",
      "Epoch 87/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9959\n",
      "Epoch 88/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9959\n",
      "Epoch 89/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9959\n",
      "Epoch 90/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9959\n",
      "Epoch 91/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9959\n",
      "Epoch 92/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9959\n",
      "Epoch 93/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9959\n",
      "Epoch 94/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9959\n",
      "Epoch 95/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9959\n",
      "Epoch 96/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9959\n",
      "Epoch 97/150\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.9959\n",
      "Epoch 98/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9959\n",
      "Epoch 99/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9959\n",
      "Epoch 100/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9959\n",
      "Epoch 101/150\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25c7c26dfd0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4 = Sequential()\n",
    "\n",
    "model_4.add(Dense(20, activation = 'relu', input_shape = (n_features, )))\n",
    "model_4.add(Dense(20, activation = 'relu'))\n",
    "model_4.add(Dense(10, activation = 'relu'))\n",
    "model_4.add(Dense(5, activation='relu'))\n",
    "model_4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_4.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_4.fit(X_train, y_train, epochs=150, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_190 (Dense)           (None, 20)                700       \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 20)                420       \n",
      "                                                                 \n",
      " dense_192 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      " dense_193 (Dense)           (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_194 (Dense)           (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1391 (5.43 KB)\n",
      "Trainable params: 1391 (5.43 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2667 - accuracy: 0.9340\n",
      "Test Accuracy: 0.934\n",
      "Test loss: 0.267\n"
     ]
    }
   ],
   "source": [
    "loss_4, acc_4 = model_4.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Accuracy: %.3f' % acc_4)\n",
    "print('Test loss: %.3f' % loss_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmeq5l1edZPg"
   },
   "source": [
    "## **Important:** Document in your lab logbook the accuracy of the improved model. Do not include any code or explanations in your lab logbook. Simply record the accuracy. For example, if the obtained accuracy is 0.98, then enter \"0.98\" in your lab logbook.\n",
    "\n",
    "## In addition to the accuracy, also document the output of the neural network as provided in Task 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFNL8fY2rd41"
   },
   "source": [
    "\n",
    "Next, we have provided the code to predict on an unknown value.\n",
    "We will cover these concepts later in the class. For now, just run the code to see the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kXV7gQRAP31u",
    "outputId": "a5092aea-3cad-4009-de83-956caa73ecba",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 225ms/step\n",
      "Predicted: 0.986\n"
     ]
    }
   ],
   "source": [
    "row = [1,0,0.99539,-0.05889,0.85243,0.02306,\n",
    "       0.83398,-0.37708,1,0.03760,0.85243,-0.17755,\n",
    "       0.59755,-0.44945,0.60536,-0.38223,0.84356,\n",
    "       -0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,\n",
    "       -0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,\n",
    "       -0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
    "yhat = model.predict([row])\n",
    "print('Predicted: %.3f' % yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNFK4kV9P31u"
   },
   "source": [
    "### Try out the same model with Keras Functional models!\n",
    "Refer to [Keras](https://keras.io/) for more details and tutorials for the same."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
